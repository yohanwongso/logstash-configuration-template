############################################
## LOGSTASH PARSER CONFIGURATION TEMPLATE ##
## CSV to Elasticsearch                   ##
## Version 1.0                            ##
## Â© 2023 Yohan                           ##
############################################

###################################################################################################################################
## Tested on SOF-ELK VM environtment.                                                                                            ##
## Procedure:                                                                                                                    ##
##  1. Put this file in /etc/logstash/parsers/                                                                                   ##
##  2. Modify this file to configure                                                                                             ##
##  3. Create 'temp' directory in /var/lib/logstash                                                                              ##
##  4. Execute this command:                                                                                                     ##
##     # /usr/share/logstash/bin/logstash --path data /var/lib/logstash/temp/ -c /etc/logstash/parsers/csv-to-elasticsearch.conf ##
###################################################################################################################################

input {
  file {
    ## (Mandatory) Define the file path
    path => "/mnt/hgfs/D/DFIR/Deep_Security_Agent (01 Mei 2023 - Now).csv"

    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  csv {
    ## (Optional) Uncomment to define the CSV's delimiter/separator.
    ## The default value is ",".
    # separator => ";"

    ## (Optional) Recomended to define the name of the columns as an array, will be used for naming the fields.
    columns => [
      "datetime","name","attacker_address","target_address","priority","device_action","device_vendor","device_product"
    ]
  }

  ## (Optional) Recomended to parse the "datetime" field which is containing the timestamp of the event.
  ## Define the formats of the timestamp as an array, and define the timezone of the timestamp.
  ## The "datetime" field will be parsed to "@timestamp" field.
  ## Ref : https://www.elastic.co/guide/en/logstash/current/plugins-filters-date.html
  date {
    match => [ "datetime", "MMM dd, yyyy hh:mm:ss a", "MMM dd, yyyy h:mm:ss a", "MMM d, yyyy hh:mm:ss a", "MMM d, yyyy h:mm:ss a" ]
    timezone => "Asia/Jakarta"
  }

  ## (Optional) Uncomment to add timestamp of the ingestion process by the Logstash.
  # ruby {
  #   code => "event.set('[event][ingested]' , Time.now.utc)"
  # }
}

output {
  ## Uncomment to push the result to Elasticsearch, define the hosts of the elasticsearch and the index name.
  # elasticsearch {
  #   hosts => "localhost:9200"
  #   index => "dfir-01-csv1"
  # }

  ## Uncomment to print out the result
  # stdout {}
}